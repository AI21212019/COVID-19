{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "pd.set_option('display.max_columns', 500)\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confirmed = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "df_deaths = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert table\n",
    "def converttable(df):\n",
    "    cols=df.columns.tolist()\n",
    "    pd_list=[]\n",
    "    for i in range(5,df.shape[1]):\n",
    "        temp_cols=cols[:4]\n",
    "        temp_cols.append(cols[i])\n",
    "    # print(temp_cols)\n",
    "        temp_pd=df[temp_cols].copy()\n",
    "        temp_pd['dt']=cols[i]\n",
    "        temp_pd.rename(columns={cols[i]:'value'},inplace=True)\n",
    "        pd_list.append(temp_pd)\n",
    "    df_new=pd.concat(pd_list,axis=0,ignore_index=True)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confirmed_new = converttable(df_confirmed)\n",
    "df_deaths_new = converttable(df_deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt format\n",
    "df_confirmed_new['dt']=pd.to_datetime(df_confirmed_new['dt'])\n",
    "df_deaths_new['dt']=pd.to_datetime(df_deaths_new['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cols\n",
    "df_confirmed_new.rename(columns = {'value': 'confirmed'}, inplace = True)\n",
    "df_deaths_new.rename(columns = {'value': 'deaths'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two tables\n",
    "df_merged = df_confirmed_new.merge(df_deaths_new[['Province/State', 'Country/Region', 'dt', 'deaths']], \n",
    "                                   on = ['Province/State', 'Country/Region', 'dt'], \n",
    "                                   how = 'inner')\n",
    "df_merged = df_merged[['Province/State', 'Country/Region', 'Lat', 'Long', 'dt', 'confirmed', 'deaths']]\n",
    "#df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and aggregate data for countries with provinces\n",
    "\n",
    "# US\n",
    "df_us = df_merged[df_merged['Country/Region'] == 'US'].copy()\n",
    "df_merged.drop(index = df_us.index, inplace = True)\n",
    "us_agg = df_us.groupby(by = 'dt').sum().copy()\n",
    "us_agg.reset_index(inplace = True)\n",
    "us_agg['Lat'] = 37.0902\n",
    "us_agg['Long'] = -95.7129\n",
    "us_agg['Province/State'] = np.nan\n",
    "us_agg['Country/Region'] = 'US'\n",
    "df_merged = pd.concat([df_merged, us_agg], sort = False, ignore_index = True)\n",
    "\n",
    "# China\n",
    "df_china = df_merged[df_merged['Country/Region'] == 'China'].copy()\n",
    "df_merged.drop(index = df_china.index, inplace = True)\n",
    "china_agg = df_china.groupby(by = 'dt').sum()\n",
    "china_agg.reset_index(inplace = True)\n",
    "china_agg['Lat'] = 35.8617\n",
    "china_agg['Long'] = 104.1954\n",
    "china_agg['Province/State'] = np.nan\n",
    "china_agg['Country/Region'] = 'China'\n",
    "df_merged = pd.concat([df_merged, china_agg], sort = False, ignore_index = True)\n",
    "\n",
    "# Canada\n",
    "df_canada = df_merged[df_merged['Country/Region'] == 'Canada'].copy()\n",
    "df_merged.drop(index = df_canada.index, inplace = True)\n",
    "canada_agg = df_canada.groupby(by = 'dt').sum()\n",
    "canada_agg.reset_index(inplace = True)\n",
    "canada_agg['Lat'] = 56.1304\n",
    "canada_agg['Long'] = -106.3468\n",
    "canada_agg['Province/State'] = np.nan\n",
    "canada_agg['Country/Region'] = 'Canada'\n",
    "df_merged = pd.concat([df_merged, canada_agg], sort = False, ignore_index = True)\n",
    "\n",
    "# Australia\n",
    "df_aus = df_merged[df_merged['Country/Region'] == 'Australia'].copy()\n",
    "df_merged.drop(index = df_aus.index, inplace = True)\n",
    "aus_agg = df_aus.groupby(by = 'dt').sum()\n",
    "aus_agg.reset_index(inplace = True)\n",
    "aus_agg['Lat'] = -25.2744\n",
    "aus_agg['Long'] = 133.7751\n",
    "aus_agg['Province/State'] = np.nan\n",
    "aus_agg['Country/Region'] = 'Australia'\n",
    "df_merged = pd.concat([df_merged, aus_agg], sort = False, ignore_index = True)\n",
    "\n",
    "# France\n",
    "df_fra = df_merged[df_merged['Country/Region'] == 'France'].copy()\n",
    "df_merged.drop(index = df_fra.index, inplace = True)\n",
    "fra_agg = df_fra.groupby(by = 'dt').sum()\n",
    "fra_agg.reset_index(inplace = True)\n",
    "fra_agg['Lat'] = 46.2276\n",
    "fra_agg['Long'] = 2.2137\n",
    "fra_agg['Province/State'] = np.nan\n",
    "fra_agg['Country/Region'] = 'France'\n",
    "df_merged = pd.concat([df_merged, fra_agg], sort = False, ignore_index = True)\n",
    "\n",
    "# Denmark\n",
    "df_den = df_merged[df_merged['Country/Region'] == 'Denmark'].copy()\n",
    "df_merged.drop(index = df_den.index, inplace = True)\n",
    "den_agg = df_den.groupby(by = 'dt').sum()\n",
    "den_agg.reset_index(inplace = True)\n",
    "den_agg['Lat'] = 56.2639\n",
    "den_agg['Long'] = 9.5018\n",
    "den_agg['Province/State'] = np.nan\n",
    "den_agg['Country/Region'] = 'Denmark'\n",
    "df_merged = pd.concat([df_merged, den_agg], sort = False, ignore_index = True)\n",
    "\n",
    "# United Kingdom\n",
    "df_uk = df_merged[df_merged['Country/Region'] == 'United Kingdom'].copy()\n",
    "df_merged.drop(index = df_uk.index, inplace = True)\n",
    "uk_agg = df_uk.groupby(by = 'dt').sum()\n",
    "uk_agg.reset_index(inplace = True)\n",
    "uk_agg['Lat'] = 56.2639\n",
    "uk_agg['Long'] = 9.5018\n",
    "uk_agg['Province/State'] = np.nan\n",
    "uk_agg['Country/Region'] = 'United Kingdom'\n",
    "df_merged = pd.concat([df_merged, uk_agg], sort = False, ignore_index = True)\n",
    "\n",
    "# Netherlands\n",
    "df_net = df_merged[df_merged['Country/Region'] == 'Netherlands'].copy()\n",
    "df_merged.drop(index = df_net.index, inplace = True)\n",
    "net_agg = df_net.groupby(by = 'dt').sum()\n",
    "net_agg.reset_index(inplace = True)\n",
    "net_agg['Lat'] = 52.1326\n",
    "net_agg['Long'] = 5.2913\n",
    "net_agg['Province/State'] = np.nan\n",
    "net_agg['Country/Region'] = 'Netherlands'\n",
    "df_merged = pd.concat([df_merged, net_agg], sort = False, ignore_index = True)\n",
    "\n",
    "# Drop column province\n",
    "df_merged.drop(columns = ['Province/State'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mortality rate\n",
    "df_merged['MortalityRate'] = df_merged['deaths']/df_merged['confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days since\n",
    "\n",
    "# Sort dataset by date ascending\n",
    "df_merged.sort_values(by = 'dt', ascending = True, inplace = True)\n",
    "\n",
    "# List of countries\n",
    "country_list = df_merged['Country/Region'].unique().tolist()\n",
    "\n",
    "# Locate day first case for each country\n",
    "first_confirmed = []\n",
    "first_50confirmed = []\n",
    "first_10deaths = []\n",
    "    \n",
    "for c in country_list:\n",
    "    tmp = df_merged[df_merged['Country/Region'] == c].copy()\n",
    "    first_confirmed.append(tmp.loc[tmp.confirmed.ne(0).idxmax(), 'dt'])\n",
    "    first_50confirmed.append(tmp.loc[(tmp.confirmed >= 50).idxmax(), 'dt'])\n",
    "    first_10deaths.append(tmp.loc[(tmp.deaths >= 10).idxmax(), 'dt'])\n",
    "\n",
    "df_first = pd.DataFrame(data = {'Country/Region': country_list, \n",
    "                                'first_confirmed': first_confirmed,\n",
    "                                'first_50confirmed': first_50confirmed,\n",
    "                                'first_10deaths': first_10deaths,\n",
    "                               } \n",
    "                       )\n",
    "\n",
    "# Convert to datetime\n",
    "df_first['first_confirmed'] = pd.to_datetime(df_first['first_confirmed'])\n",
    "df_first['first_50confirmed'] = pd.to_datetime(df_first['first_50confirmed'])\n",
    "df_first['first_10deaths'] = pd.to_datetime(df_first['first_10deaths'])\n",
    "\n",
    "#df_first.head()\n",
    "\n",
    "# Merge firsts with main table\n",
    "df_merged = df_merged.merge(df_first, on = 'Country/Region', how = 'left')\n",
    "\n",
    "# Convert data type\n",
    "df_merged['dt'] = pd.to_datetime(df_merged['dt'])\n",
    "\n",
    "# Calculate days since\n",
    "df_merged['days_since_1st_conf'] = df_merged['dt'] - df_merged['first_confirmed']\n",
    "df_merged['days_since_50th_conf'] = df_merged['dt'] - df_merged['first_50confirmed']\n",
    "df_merged['days_since_10th_deaths'] = df_merged['dt'] - df_merged['first_10deaths']\n",
    "\n",
    "# Transform date units\n",
    "df_merged['days_since_1st_conf'] = df_merged['days_since_1st_conf'].dt.days\n",
    "df_merged['days_since_50th_conf'] = df_merged['days_since_50th_conf'].dt.days\n",
    "df_merged['days_since_10th_deaths'] = df_merged['days_since_10th_deaths'].dt.days\n",
    "\n",
    "# Drop intermediate columns\n",
    "df_merged.drop(columns = ['first_confirmed', 'first_50confirmed', 'first_10deaths'], inplace = True)\n",
    "\n",
    "#df_merged[df_merged['Country/Region'] == 'Germany'][['dt', 'confirmed', 'deaths', 'days_since_1st_conf',\n",
    "#                                                     'days_since_50th_conf', 'days_since_10th_deaths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New cases\n",
    "\n",
    "# Sort values\n",
    "df_merged.sort_values(by = ['Country/Region', 'dt'], ascending = True, inplace = True)\n",
    "\n",
    "# Differences\n",
    "df_merged['confirmed_newcases'] = df_merged.groupby(by = ['Country/Region']).confirmed.diff()\n",
    "df_merged['deaths_newcases'] = df_merged.groupby(by = ['Country/Region']).deaths.diff()\n",
    "\n",
    "#df_merged[df_merged['Country/Region'] == 'Germany'][['dt', 'confirmed', 'confirmed_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New cases moving average\n",
    "df_merged['confirmed_newcases_movavg'] = np.nan\n",
    "df_merged['deaths_newcases_movavg'] = np.nan\n",
    "\n",
    "days_num = df_merged['dt'].unique().shape[0]\n",
    "\n",
    "for c in country_list:\n",
    "    \n",
    "    tmp = df_merged[df_merged['Country/Region'] == c].copy()\n",
    "    tmp = tmp.sort_values(by = 'dt').reset_index()\n",
    "    \n",
    "    for i in range(1, days_num-1):\n",
    "        \n",
    "        df_merged.loc[tmp.loc[i,'index'], 'confirmed_newcases_movavg'] = ((\n",
    "            tmp.loc[i-1, 'confirmed_newcases'] +\n",
    "            tmp.loc[i, 'confirmed_newcases'] +\n",
    "            tmp.loc[i+1, 'confirmed_newcases'] )/3) \n",
    "        \n",
    "        df_merged.loc[tmp.loc[i,'index'], 'deaths_newcases_movavg'] = ((\n",
    "            tmp.loc[i-1, 'deaths_newcases'] +\n",
    "            tmp.loc[i, 'deaths_newcases'] +\n",
    "            tmp.loc[i+1, 'deaths_newcases'] )/3)    \n",
    "        \n",
    "\n",
    "# Check\n",
    "#df_merged[df_merged['Country/Region'] == 'Germany'][['dt', 'confirmed', 'confirmed_newcases', \n",
    "#                                                     'confirmed_newcases_growth', \n",
    "#                                                     'confirmed_newcases_growth_movavg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'world_pop_by_country.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2eff6f18d349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Open population table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_pop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'world_pop_by_country.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_pop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Country Name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Country/Region'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2018'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'population_2018'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Merge population table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'world_pop_by_country.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Open population table\n",
    "df_pop = pd.read_csv('../data_tables/world_pop_by_country.csv')\n",
    "df_pop.rename(columns = {'Country Name': 'Country/Region', '2018': 'population_2018'}, inplace = True)\n",
    "\n",
    "# Merge population table\n",
    "df_merged = df_merged.merge(df_pop, on = 'Country/Region', how = 'left')\n",
    "\n",
    "#df_merged.sort_values('dt').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cases by 100.000 hab.\n",
    "df_merged['confirmed_by100000pop'] = df_merged['confirmed']*100000/df_merged['population_2018']\n",
    "df_merged['deaths_by100000pop'] = df_merged['deaths']*100000/df_merged['population_2018']\n",
    "\n",
    "# Drop intermediate columns\n",
    "df_merged.drop(columns = ['Country Code', 'population_2018'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New cases growth (new cases today divided by new cases yesterday)\n",
    "\n",
    "df_merged['confirmed_newcases_growth'] = np.nan\n",
    "df_merged['deaths_newcases_growth'] = np.nan\n",
    "\n",
    "for c in country_list:\n",
    "    \n",
    "    tmp = df_merged[df_merged['Country/Region'] == c]\n",
    "    tmp = tmp.sort_values(by = 'dt').reset_index()\n",
    "    \n",
    "    for i in range(1, days_num):\n",
    "        if (tmp.loc[i-1, 'confirmed_newcases'] != 0):\n",
    "            df_merged.loc[tmp.loc[i,'index'] , 'confirmed_newcases_growth'] = (\n",
    "                tmp.loc[i, 'confirmed_newcases']/tmp.loc[i-1, 'confirmed_newcases'])\n",
    "        else:\n",
    "            df_merged.loc[tmp.loc[i,'index'] , 'confirmed_newcases_growth'] = np.nan\n",
    "        if (tmp.loc[i-1, 'deaths_newcases'] != 0):\n",
    "            df_merged.loc[tmp.loc[i,'index'] , 'deaths_newcases_growth'] = (\n",
    "                tmp.loc[i, 'deaths_newcases']/tmp.loc[i-1, 'deaths_newcases'])\n",
    "        else:\n",
    "            df_merged.loc[tmp.loc[i,'index'] , 'deaths_newcases_growth'] = np.nan\n",
    "        \n",
    "#df_merged[df_merged['Country/Region'] == 'Germany'][['dt', 'confirmed', 'confirmed_newcases', \n",
    "#                                                     'confirmed_newcases_growth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New cases growth moving average\n",
    "\n",
    "df_merged['confirmed_newcases_growth_movavg'] = np.nan\n",
    "df_merged['deaths_newcases_growth_movavg'] = np.nan\n",
    "\n",
    "for c in country_list:\n",
    "    \n",
    "    tmp = df_merged[df_merged['Country/Region'] == c].copy()\n",
    "    tmp = tmp.sort_values(by = 'dt').reset_index()\n",
    "    \n",
    "    for i in range(1, days_num-1):\n",
    "        \n",
    "        df_merged.loc[tmp.loc[i,'index'], 'confirmed_newcases_growth_movavg'] = ((\n",
    "            tmp.loc[i-1, 'confirmed_newcases_growth'] +\n",
    "            tmp.loc[i, 'confirmed_newcases_growth'] +\n",
    "            tmp.loc[i+1, 'confirmed_newcases_growth'] )/3) \n",
    "        \n",
    "        df_merged.loc[tmp.loc[i,'index'], 'deaths_newcases_growth_movavg'] = ((\n",
    "            tmp.loc[i-1, 'deaths_newcases_growth'] +\n",
    "            tmp.loc[i, 'deaths_newcases_growth'] +\n",
    "            tmp.loc[i+1, 'deaths_newcases_growth'] )/3)    \n",
    "        \n",
    "\n",
    "# Check\n",
    "#df_merged[df_merged['Country/Region'] == 'Germany'][['dt', 'confirmed', 'confirmed_newcases', \n",
    "#                                                     'confirmed_newcases_growth', \n",
    "#                                                     'confirmed_newcases_growth_movavg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data for plotting\n",
    "\n",
    "# Data for the top 10 countries in number of confirmed cases\n",
    "last_date = df_merged['dt'].max()\n",
    "top10 = df_merged[df_merged['dt'] == last_date].sort_values(by = 'confirmed', ascending = False).iloc[0:10, :] \n",
    "top10_country = top10['Country/Region'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting colors\n",
    "top10_col = ['blue', 'orange', 'green', 'crimson', 'grey', 'turquoise', 'yellowgreen', 'steelblue', 'purple',\n",
    "             'pink'\n",
    "            ]\n",
    "title_col = 'navy'\n",
    "subtitle_col = 'grey'\n",
    "label_col = 'dimgray'\n",
    "#bg_col =\n",
    "#grid_col =\n",
    "\n",
    "# Plottoing fonts & sizes\n",
    "title_font = 'PT Sans Narrow'\n",
    "subtitle_font = 'PT Sans Narrow'\n",
    "label_font = 'PT Sans'\n",
    "title_size = 24\n",
    "subtitle_size = 18\n",
    "label_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "for i, c in enumerate(top10_country):\n",
    "    data = []\n",
    "    nc = df_merged[df_merged['Country/Region'] == c].confirmed_newcases_movavg\n",
    "    data.append(go.Scatter(x = df_merged[df_merged['Country/Region'] == c].dt,\n",
    "                           y = nc,\n",
    "                           name = '3-day moving average',\n",
    "                           marker = dict(color = 'orange'),\n",
    "                           hoverinfo = 'text',\n",
    "                           hovertext = ['{:.0f}'.format(i) for i in nc],\n",
    "                           hoverlabel = dict(bordercolor = 'gray',\n",
    "                                             bgcolor = 'white',\n",
    "                                             font = dict(color = 'gray'),\n",
    "                                             )\n",
    "                           )\n",
    "                )\n",
    "        #data.append(go.Bar(x = df_merged[df_merged['Country/Region'] == c].dt,\n",
    "        #               y = df_merged[df_merged['Country/Region'] == c].confirmed_newcases,\n",
    "        #               name = 'Actual data',\n",
    "        #               opacity = 0.2,\n",
    "        #               marker = dict(color = 'orange'),\n",
    "        #               hoverinfo = 'x+y',\n",
    "        #               hovertext = c,\n",
    "        #               hoverlabel = dict(bordercolor = 'gray',\n",
    "        #                                 bgcolor = 'white',\n",
    "        #                                 font = dict(color = 'gray'),\n",
    "        #                                 ),\n",
    "        #               )\n",
    "        #        )\n",
    "    lay = go.Layout(width = 800,\n",
    "                    height = 500,\n",
    "                    xaxis = dict(title='Date',\n",
    "                                 nticks = 10,\n",
    "                                 rangemode = 'nonnegative',\n",
    "                                 zeroline = False,\n",
    "                                 ),\n",
    "                    yaxis = dict(title='Confirmed cases',\n",
    "                                 type = 'linear',\n",
    "                                 ),\n",
    "                    hovermode = 'closest',\n",
    "                    font = dict(size = label_size,\n",
    "                                family = label_font,\n",
    "                                color = label_col,\n",
    "                                ),\n",
    "                    legend = dict(x = 1.03,\n",
    "                                  y = 0.8),\n",
    "                    annotations=[dict(x = 0.02,\n",
    "                                      y = 1.2,\n",
    "                                      showarrow = False,\n",
    "                                      text = 'Has the curve flattened?',\n",
    "                                      xref = 'paper',\n",
    "                                      yref = 'paper',\n",
    "                                      font=dict(family = title_font,\n",
    "                                                size = title_size,\n",
    "                                                color = title_col,),\n",
    "                                      ),\n",
    "                                 dict(x = 0.02,\n",
    "                                      y = 1.1,\n",
    "                                      showarrow = False,\n",
    "                                      text = 'New cases confirmed each day (3-day average)',\n",
    "                                      xref = 'paper',\n",
    "                                      yref = 'paper',\n",
    "                                      font=dict(family = subtitle_font,\n",
    "                                                size = subtitle_size,\n",
    "                                                color = subtitle_col,),\n",
    "                                      ),\n",
    "                                 dict(x = 0.08,\n",
    "                                      y = 0.85,\n",
    "                                      showarrow = False,\n",
    "                                      text = c,\n",
    "                                      xref = 'paper',\n",
    "                                      yref = 'paper',\n",
    "                                      font=dict(family = subtitle_font,\n",
    "                                                size = subtitle_size,\n",
    "                                                color = 'orange',),\n",
    "                                      ),\n",
    "                                 ],\n",
    "                    )\n",
    "    fig = dict(data=[data[0]], layout=lay)\n",
    "    plot = plotly.offline.plot({'data':data,\n",
    "                               'layout':lay},\n",
    "                               include_plotlyjs = False,\n",
    "                               output_type = 'div',\n",
    "                               config = dict(showLink = False,\n",
    "                                             modeBarButtonsToRemove = ['sendDataToCloud'],\n",
    "                                             displaylogo = False,\n",
    "                                             responsive = True)\n",
    "                               )\n",
    "    # Save JS\n",
    "    out_file = open('../vtimeline_newcases_date_'+str(i)+'.html', 'w')\n",
    "    out_file.write('<!DOCTYPE html><html><head><script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script></head><body>')\n",
    "    out_file.write(plot)\n",
    "    out_file.write('</body><html>')\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend to JSON\n",
    "most_recent_day = df_merged.sort_values('dt').dt.unique()[-2]\n",
    "tmp = df_merged[ (df_merged['dt'] == most_recent_day) & (df_merged['Country/Region'].isin(top10_country))].copy()\n",
    "\n",
    "def up_or_down(x):\n",
    "    if (x>=1):\n",
    "        return 'up'\n",
    "    else:\n",
    "        return 'down'\n",
    "\n",
    "tmp['trend'] = tmp.apply(lambda x: up_or_down(x['confirmed_newcases_growth_movavg']), axis=1)\n",
    "tmp = tmp[['Country/Region', 'trend']]\n",
    "tmp.set_index('Country/Region', inplace = True)\n",
    "tmp.to_json('trends.json', orient = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
